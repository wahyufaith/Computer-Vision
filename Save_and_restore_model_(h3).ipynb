{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save and restore model (h3).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkYN4MzQvm+X233DSI1d0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wahyufaith/Computer-Vision/blob/main/Save_and_restore_model_(h3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JgdTgMWByaJ"
      },
      "source": [
        "#**WAHYU PEBRIANTO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCpV3DXBpHbB",
        "outputId": "4ab24672-6cc6-43ee-c498-5d462af1dd91"
      },
      "source": [
        "!pip install pyyaml h5py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5; python_version == \"3.7\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHh2InIUphDN",
        "outputId": "4de7d28d-96a6-41f6-c529-526940542bfb"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sWI-4A6ppTF"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "#print(len(train_images))\n",
        "#print(len(test_images))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smKTsZC1ppe8"
      },
      "source": [
        "train_labels = train_labels[:1000]\n",
        "test_labels  = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28*28)/255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28*28)/255.0"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXBxFStJtJ9j"
      },
      "source": [
        "**Mendefinisak model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcIzW9ROpph-",
        "outputId": "bba731d0-158e-4925-ba20-87eb9da105ce"
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "                               keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "                               keras.layers.Dropout(0.2),\n",
        "                               keras.layers.Dense(10)\n",
        "                               ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ohAp2U2ywH"
      },
      "source": [
        "# **1. MENYIMPAN WEIGHT MODEL YANG DI TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG0U53sqybf7"
      },
      "source": [
        "# **Save checkpoints during training**\n",
        "\n",
        "1. Kita dapat menggunakan per-trained model tanpa harus mentraining kembali, atau mengambil training yang Kita tinggalkan jika proses training terganggu. **(The tf.keras.callbacks.ModelCheckpointcallback)** memungkinkan kita untuk terus menyimpan model baik selama proses dan pada akhir training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czP6-tV-zXGR"
      },
      "source": [
        "**Checkpoint callback usage**\n",
        "\n",
        "Create a (tf.keras.callbacks.ModelCheckpoint) callback that saves weights only during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD9NBlHRxEcN",
        "outputId": "54b53209-7abc-4a35-e114-e38297b8138c"
      },
      "source": [
        "checkpoint_path = \"/content/sample_data/training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_images, \n",
        "          train_labels,  \n",
        "          epochs=10,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=[cp_callback])  # Pass callback to training\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 1s 9ms/step - loss: 1.1279 - sparse_categorical_accuracy: 0.6930 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.7720\n",
            "\n",
            "Epoch 00001: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4095 - sparse_categorical_accuracy: 0.8940 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.8130\n",
            "\n",
            "Epoch 00002: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3061 - sparse_categorical_accuracy: 0.9180 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.8530\n",
            "\n",
            "Epoch 00003: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2052 - sparse_categorical_accuracy: 0.9530 - val_loss: 0.4384 - val_sparse_categorical_accuracy: 0.8560\n",
            "\n",
            "Epoch 00004: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.4467 - val_sparse_categorical_accuracy: 0.8530\n",
            "\n",
            "Epoch 00005: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1214 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.4138 - val_sparse_categorical_accuracy: 0.8630\n",
            "\n",
            "Epoch 00006: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8460\n",
            "\n",
            "Epoch 00007: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.4016 - val_sparse_categorical_accuracy: 0.8710\n",
            "\n",
            "Epoch 00008: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.4194 - val_sparse_categorical_accuracy: 0.8630\n",
            "\n",
            "Epoch 00009: saving model to /content/sample_data/training_1/cp.ckpt\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.4234 - val_sparse_categorical_accuracy: 0.8640\n",
            "\n",
            "Epoch 00010: saving model to /content/sample_data/training_1/cp.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2a523c2790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2j46ozL3fp3"
      },
      "source": [
        "Tindakan ini akan membuat satu kumpulan TensorFlow checkpoint files yang diperbarui di akhir setiap epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia_PW3bI0WMx",
        "outputId": "1d65ff24-6be4-4309-ef65-78cdffd9f6dd"
      },
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp.ckpt.index', 'checkpoint', 'cp.ckpt.data-00000-of-00001']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8fYJz5o3qit"
      },
      "source": [
        "Selama dua model berbagi arsitektur yang sama, Anda dapat berbagi weight di antara keduanya. Jadi, saat memulihkan model dari weight, buat model dengan arsitektur yang sama dengan model aslinya, lalu atur weightnya.\n",
        "\n",
        "Sekarang buat kembali model baru yang tidak terlatih dan evaluasi pada set pengujian. Model yang tidak terlatih akan tampil pada tingkat kebetulan (~10% accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tbLJ7Nc0iAB",
        "outputId": "ce9236af-0989-48f3-e671-79ad23c2f2e3"
      },
      "source": [
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 2.3175 - sparse_categorical_accuracy: 0.1280\n",
            "Untrained model, accuracy: 12.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgOG6CSH4Xh1"
      },
      "source": [
        "**Kemudian muat weight dari checkpoint dan evaluasi kembali:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IajzuLRP0iDA",
        "outputId": "ddf9f284-f264-4c89-ca6f-c169db40f671"
      },
      "source": [
        "# Loads the weights\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4234 - sparse_categorical_accuracy: 0.8640\n",
            "Restored model, accuracy: 86.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogblo2Uu4trc"
      },
      "source": [
        "# **2. MENYIMPAN MODEL YANG DI TRAINING PADA SETIAP EPOCH/SIMPAN EPOCH MODEL**\n",
        "\n",
        "\n",
        "Latih model baru, dan simpan checkpoint bernama unik setiap 5 epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_yqrLDJ0iFx",
        "outputId": "55e19eeb-4d2e-4543-ba75-6cb4c7e92355"
      },
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"/content/sample_data/training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size)\n",
        "\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_images, \n",
        "          train_labels,\n",
        "          epochs=50, \n",
        "          batch_size=batch_size, \n",
        "          callbacks=[cp_callback],\n",
        "          validation_data=(test_images, test_labels),\n",
        "          verbose=0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "\n",
            "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
            "\n",
            "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
            "\n",
            "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
            "\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "\n",
            "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
            "\n",
            "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
            "\n",
            "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
            "\n",
            "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
            "\n",
            "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2a4eb915d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsdus6t35xgi"
      },
      "source": [
        "Sekarang, lihat checkpoint yang dihasilkan dan pilih yang terbaru:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu_WhvAq0iIq",
        "outputId": "6636a18c-c810-437f-812a-f8a8d8b7ddff"
      },
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp-0035.ckpt.data-00000-of-00001',\n",
              " 'cp-0020.ckpt.data-00000-of-00001',\n",
              " 'cp-0035.ckpt.index',\n",
              " 'cp-0015.ckpt.index',\n",
              " 'cp-0020.ckpt.index',\n",
              " 'cp-0030.ckpt.data-00000-of-00001',\n",
              " 'cp-0040.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.data-00000-of-00001',\n",
              " 'cp-0005.ckpt.data-00000-of-00001',\n",
              " 'cp-0010.ckpt.index',\n",
              " 'cp-0000.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.index',\n",
              " 'cp-0025.ckpt.data-00000-of-00001',\n",
              " 'cp-0005.ckpt.index',\n",
              " 'cp-0000.ckpt.index',\n",
              " 'cp-0045.ckpt.index',\n",
              " 'cp-0045.ckpt.data-00000-of-00001',\n",
              " 'cp-0015.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.index',\n",
              " 'checkpoint',\n",
              " 'cp-0040.ckpt.index',\n",
              " 'cp-0030.ckpt.index',\n",
              " 'cp-0010.ckpt.data-00000-of-00001']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1-b0mJsj0iLI",
        "outputId": "e49ebf02-c30c-467a-83ab-96bf8d96c544"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNcdYIdN6CTt"
      },
      "source": [
        "**Catatan: format TensorFlow default hanya menyimpan 5 checkpoint terbaru.**\n",
        "\n",
        "Untuk menguji, setel ulang model dan muat checkpoint terbaru:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DuU2PGD0iN9",
        "outputId": "a91a83da-3c4e-444a-e847-1c4be618d031"
      },
      "source": [
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Load the previously saved weights\n",
        "model.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4865 - sparse_categorical_accuracy: 0.8730\n",
            "Restored model, accuracy: 87.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qmbv0w46bCE"
      },
      "source": [
        "##**Apa saja file-file ini?**\n",
        "Kode di atas menyimpan weight ke kumpulan file berformat checkpoint yang hanya berisi weight terlatih dalam format biner. checkpoint berisi:\n",
        "\n",
        "- Satu atau beberapa pecahan yang berisi weight model Kita.\n",
        "- File indeks yang menunjukkan weight mana yang disimpan.\n",
        "\n",
        "\n",
        "Jika Kita melatih model pada satu mesin, kita akan memiliki satu pecahan dengan akhiran: **.data-00000-of-00001**\n",
        "\n",
        "##**Simpan bobot secara manual Manual**\n",
        "\n",
        "Menyimpan weight secara manual dengan **Model.save_weightsmetode.** Secara default, **tf.keras—** dan **save_weights** khususnya—menggunakan format checkpoint TensorFlow dengan **.ckpt** ekstensi (menyimpan dalam **HDF5** dengan **.h5** ekstensi tercakup dalam panduan Menyimpan dan membuat serial model ):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V4fvxNi0iQg",
        "outputId": "c16c5617-064b-44c5-f50a-2dc1171f3f1e"
      },
      "source": [
        "# Save the weights\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4865 - sparse_categorical_accuracy: 0.8730\n",
            "Restored model, accuracy: 87.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQC9qzsM8LBR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMpscvx_8LEo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5u5ZUfV8cuw"
      },
      "source": [
        "# **3. Simpan seluruh model**\n",
        "\n",
        "format jika kita akan menyimpan seluruh file model yaitu : **(SavedModel dan HDF5)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRYR1ZPP9GUh"
      },
      "source": [
        "###**a).** Format **SavedModel**\n",
        "\n",
        "\n",
        "Format **SavedModel** adalah cara lain untuk membuat serial model. Model yang disimpan dalam format ini dapat dipulihkan menggunakan **tf.keras.models.load_model** dan kompatibel dengan **TensorFlow Serving**.\n",
        "\n",
        "**SavedModel** panduan masuk ke detail tentang bagaimana serving/memeriksa **SavedModel**. Bagian di bawah ini mengilustrasikan langkah-langkah untuk save dan merestore model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZF2VsRK8LHf",
        "outputId": "f98d8778-6ae8-4a9c-e36d-934c7aaaa2d4"
      },
      "source": [
        "# Create and train a new model instance.\n",
        "model = create_model()\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Save the entire model as a SavedModel.\n",
        "#!mkdir -p saved_model\n",
        "model.save('/content/sample_data/saved_model/my_model')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.1562 - sparse_categorical_accuracy: 0.6510\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4299 - sparse_categorical_accuracy: 0.8770\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2829 - sparse_categorical_accuracy: 0.9260\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9520\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1429 - sparse_categorical_accuracy: 0.9740\n",
            "INFO:tensorflow:Assets written to: /content/sample_data/saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5ioIF6c-i0e"
      },
      "source": [
        "Format **SavedModel** adalah direktori yang berisi **biner protobuf** dan **checpoint TensorFlow**.\n",
        "\n",
        "Periksa direktori model yang disimpan:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJd_zKIf8LJ5",
        "outputId": "07791a9f-9be6-4319-837d-552377312008"
      },
      "source": [
        "# my_model directory\n",
        "#!ls /content/sample_data/saved_model/\n",
        "\n",
        "# Contains an assets folder, saved_model.pb, and variables folder.\n",
        "!ls /content/sample_data/saved_model/my_model"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7n1eSwa_oie"
      },
      "source": [
        "**Setelah kita menyimpan model, coba muat ulang model Keras baru dari model yang telah disimpan:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHb4ENHM8LM8",
        "outputId": "bf105579-2f26-4911-df5b-91051bf8e7a8"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/sample_data/saved_model/my_model')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtoQWpP0_5Ik"
      },
      "source": [
        "**Model yang dipulihkan dikompilasi dengan argumen yang sama dengan model aslinya. Coba jalankan evaluasi dan prediksi dengan model yang dimuat:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMulJ_Pi8LPr",
        "outputId": "5fc09878-d804-4637-a2bd-26412f77b211"
      },
      "source": [
        "# Evaluate the restored model\n",
        "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "print(new_model.predict(test_images).shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4152 - sparse_categorical_accuracy: 0.8640\n",
            "Restored model, accuracy: 86.40%\n",
            "(1000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8JBRlklAK4b"
      },
      "source": [
        "##**b).** Format **HDF5**\n",
        "\n",
        "\n",
        "Keras menyediakan format penyimpanan dasar menggunakan standar HDF5 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJdbOWXN8LSo",
        "outputId": "17d285b2-448c-425d-f418-a06725c8e18b"
      },
      "source": [
        "# Create and train a new model instance.\n",
        "model = create_model()\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Save the entire model to a HDF5 file.\n",
        "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
        "model.save('/content/sample_data/my_model.h5')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.1970 - sparse_categorical_accuracy: 0.6630\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4401 - sparse_categorical_accuracy: 0.8620\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3054 - sparse_categorical_accuracy: 0.9140\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2253 - sparse_categorical_accuracy: 0.9460\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3nxM5SiAkMq"
      },
      "source": [
        "**Sekarang, buat ulang model dari file itu:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u98KREU8LVR",
        "outputId": "dfd7087a-0da6-42c8-dd22-c6d6052160e4"
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('/content/sample_data/my_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIrsHk5MA9tK"
      },
      "source": [
        "**Periksa keakuratannya:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XayT4SZ8LYR",
        "outputId": "0313d5ad-84d6-495a-812d-fc56bd129506"
      },
      "source": [
        "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4253 - sparse_categorical_accuracy: 0.8650\n",
            "Restored model, accuracy: 86.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5z5QxGHBYQN"
      },
      "source": [
        "##KETERANGAN\n",
        "Perbedaan utama antara **HDF5** dan **SavedModel** adalah bahwa **HDF5** menggunakan konfigurasi objek untuk menyimpan arsitektur model, sedangkan **SavedModel** menyimpan grafik eksekusi. Dengan demikian, **SavedModels** dapat menyimpan objek khusus seperti model subkelas dan lapisan khusus tanpa memerlukan kode asli."
      ]
    }
  ]
}